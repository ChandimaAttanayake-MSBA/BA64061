# -*- coding: utf-8 -*-
"""Creitd_Card_Fraud (2).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Nml4g2gsT-GEg9YIMNnbpnCpzgZFyHNb
"""

# Financial Fraud Detection - Complete Balanced Implementation
## 1. Install Required Packages
!pip install tensorflow scikit-learn imbalanced-learn transformers > /dev/null

## 2. Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# 3. Load Data from Google Drive
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Update this path to your dataset location in Drive
data_path = '/content/drive/MyDrive/Colab Notebooks/Fraud Detection/creditcard.csv'
df = pd.read_csv(data_path)

# Verify load
print("Data loaded successfully. Shape:", df.shape)
display(df.head())

# Feature engineering
scaler = RobustScaler()
df['Amount'] = scaler.fit_transform(df['Amount'].values.reshape(-1,1))
df['Time'] = scaler.fit_transform(df['Time'].values.reshape(-1,1))
X = df.drop('Class', axis=1)
y = df['Class']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

## 5. Data Preprocessing
from sklearn.preprocessing import RobustScaler
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE

# Normalize Time and Amount
scaler = RobustScaler()
df['Amount'] = scaler.fit_transform(df['Amount'].values.reshape(-1,1))
df['Time'] = scaler.fit_transform(df['Time'].values.reshape(-1,1))

# Train-test split
X = df.drop('Class', axis=1)
y = df['Class']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

# Handle imbalance with SMOTE
sm = SMOTE(random_state=42)
X_train_res, y_train_res = sm.fit_resample(X_train, y_train)

print("\nClass distribution after SMOTE:")
print(pd.Series(y_train_res).value_counts())

## 2. LSTM Model (Improved Version)
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout

def create_sequences(data, labels, seq_length=30):
    seq, targets = [], []
    for i in range(seq_length, len(data)):
        seq.append(data.iloc[i-seq_length:i].values)
        targets.append(labels.iloc[i])
    return np.array(seq), np.array(targets)

X_train_seq, y_train_seq = create_sequences(pd.DataFrame(X_train), y_train)
X_test_seq, y_test_seq = create_sequences(pd.DataFrame(X_test), y_test)

lstm_model = Sequential([
    LSTM(64, input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])),
    Dropout(0.3),
    Dense(1, activation='sigmoid')
])
lstm_model.compile(optimizer='adam', loss='binary_crossentropy',
                  metrics=['Precision', 'Recall', 'AUC'])

# Train with class weights
history = lstm_model.fit(X_train_seq, y_train_seq, epochs=15, batch_size=64,
                        validation_split=0.1, class_weight={0:1, 1:30})

## 3. Autoencoder Model
from tensorflow.keras import Model, Input

input_dim = X_train.shape[1]
encoding_dim = 14

input_layer = Input(shape=(input_dim,))
encoder = Dense(encoding_dim, activation='relu')(input_layer)
decoder = Dense(input_dim, activation='sigmoid')(encoder)

autoencoder = Model(inputs=input_layer, outputs=decoder)
autoencoder.compile(optimizer='adam', loss='mse')

# Train on normal transactions only
normal_idx = y_train == 0
autoencoder.fit(X_train[normal_idx], X_train[normal_idx],
               epochs=20, batch_size=64, validation_split=0.1)

# 1. TRANSFORMER IMPLEMENTATION
from tensorflow.keras.layers import LayerNormalization, MultiHeadAttention, Embedding, GlobalAveragePooling1D
from tensorflow.keras import Input, Model

class TransformerBlock(tf.keras.layers.Layer):
    def __init__(self, embed_dim, num_heads):
        super().__init__()
        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)
        self.layernorm1 = LayerNormalization()
        self.layernorm2 = LayerNormalization()
        self.dense = tf.keras.Sequential([
            Dense(embed_dim, activation='gelu'),
            Dense(embed_dim)
        ])

    def call(self, inputs):
        attn_output = self.att(inputs, inputs)
        out1 = self.layernorm1(inputs + attn_output)
        ff_output = self.dense(out1)
        return self.layernorm2(out1 + ff_output)

def build_transformer_model(input_shape):
    inputs = Input(shape=input_shape)

    # Feature Embedding
    x = Dense(64)(inputs)

    # Positional Encoding
    positions = tf.range(start=0, limit=input_shape[0], delta=1)
    position_embedding = Embedding(input_dim=input_shape[0], output_dim=64)(positions)
    x += position_embedding

    # Transformer Blocks
    x = TransformerBlock(embed_dim=64, num_heads=4)(x)
    x = GlobalAveragePooling1D()(x)
    outputs = Dense(1, activation='sigmoid')(x)

    model = Model(inputs=inputs, outputs=outputs)
    model.compile(optimizer='adam',
                 loss='binary_crossentropy',
                 metrics=['Precision', 'Recall', 'AUC'])
    return model

# 2. DATA PREPARATION FOR TRANSFORMER
# Using same sequences as LSTM for fair comparison
X_train_trans = X_train_seq
y_train_trans = y_train_seq
X_test_trans = X_test_seq
y_test_trans = y_test_seq

# 3. TRAINING THE TRANSFORMER
transformer = build_transformer_model(X_train_trans.shape[1:])
transformer.fit(X_train_trans, y_train_trans,
                epochs=15,
                batch_size=64,
                validation_split=0.1,
                class_weight={0:1, 1:30})

## 5. Comparative Evaluation
def evaluate_model(model, X_test, y_test, model_type='lstm'):
    if model_type == 'autoencoder':
        reconstructions = model.predict(X_test)
        mse = np.mean(np.power(X_test - reconstructions, 2), axis=1)
        y_pred = (mse > np.percentile(mse, 95)).astype(int)  # Anomaly threshold
    else:
        y_pred = (model.predict(X_test) > 0.5).astype(int)

    from sklearn.metrics import classification_report
    print(classification_report(y_test, y_pred))

print("LSTM Performance:")
evaluate_model(lstm_model, X_test_seq, y_test_seq)

print("\nAutoencoder Performance:")
evaluate_model(autoencoder, X_test, y_test, 'autoencoder')

print("\n=== Transformer Evaluation ===")
evaluate_model(transformer, X_test_trans, y_test_trans)