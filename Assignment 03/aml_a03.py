# -*- coding: utf-8 -*-
"""AML A03.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PRxOPrOtk_KikAVKgV77SrE8LWpA1Mam
"""

# 1. Mount Google Drive and Setup
from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import os

# Set random seeds for reproducibility
tf.random.set_seed(42)
np.random.seed(42)

# Check TensorFlow version
print("TensorFlow version:", tf.__version__)

# 2. Load Data from Google Drive
# Update this path to your dataset location in Google Drive
drive_path = '/content/drive/MyDrive/Colab Notebooks/jena_climate_2009_2016.csv/jena_climate_2009_2016.csv'

try:
    df = pd.read_csv(drive_path)
    print("File loaded successfully from Google Drive!")

    # Display basic info
    print("\nDataset shape:", df.shape)
    print("\nFirst 5 rows:")
    display(df.head())

except Exception as e:
    print(f"Error loading file: {e}")
    print("\nTroubleshooting steps:")
    print("1. Make sure you've mounted Google Drive correctly")
    print("2. Verify the file exists at the specified path")
    print("3. Check the filename is exactly 'jena_climate_2009_2016.csv'")
    print("4. Ensure you have permission to access the file")

# 3. Data Preparation
# Extract numerical data (skip Date Time column)
data = df.iloc[:, 1:].values.astype('float32')

def prepare_data(data, split_fraction=0.715):
    train_split = int(split_fraction * data.shape[0])

    # Normalize using training set statistics
    mean = data[:train_split].mean(axis=0)
    std = data[:train_split].std(axis=0)

    data -= mean
    data /= std

    return data, mean, std

data, mean, std = prepare_data(data)

# Parameters for time-series windows
sampling_rate = 6
sequence_length = 120
delay = sampling_rate * (sequence_length + 24 - 1)
batch_size = 256

def create_dataset(data, sequence_length, delay, sampling_rate, batch_size, shuffle=False):
    dataset = keras.utils.timeseries_dataset_from_array(
        data[:-delay],
        targets=data[delay:][:, 1],  # Temperature is column 1
        sampling_rate=sampling_rate,
        sequence_length=sequence_length,
        shuffle=shuffle,
        batch_size=batch_size,
    )
    return dataset

train_dataset = create_dataset(data[:200000], sequence_length, delay, sampling_rate, batch_size, shuffle=True)
val_dataset = create_dataset(data[200000:300000], sequence_length, delay, sampling_rate, batch_size)
test_dataset = create_dataset(data[300000:], sequence_length, delay, sampling_rate, batch_size)

print(f"\nTraining samples: {len(train_dataset)*batch_size}")
print(f"Validation samples: {len(val_dataset)*batch_size}")
print(f"Test samples: {len(test_dataset)*batch_size}")

# 4. Model Training Function
def train_and_evaluate_model(model, train_data, val_data, test_data, epochs=10, model_name="Model"):
    model.compile(optimizer="rmsprop", loss="mse", metrics=["mae"])

    print(f"\nTraining {model_name}...")
    history = model.fit(
        train_data,
        epochs=epochs,
        validation_data=val_data,
        verbose=1
    )

    plt.figure(figsize=(10, 5))
    plt.plot(history.history["mae"], label="Training MAE")
    plt.plot(history.history["val_mae"], label="Validation MAE")
    plt.title(f"{model_name} - Training History")
    plt.xlabel("Epochs")
    plt.ylabel("MAE")
    plt.legend()
    plt.show()

    print("\nTest evaluation:")
    test_results = model.evaluate(test_data, verbose=0)
    print(f"Test MAE: {test_results[1]:.4f}")
    print(f"Test MSE: {test_results[0]:.4f}")

    return test_results

# 5. Model Architectures
# Model 1: Baseline GRU
print("\n" + "="*50)
print("Building Baseline GRU Model")
print("="*50)
model1 = keras.Sequential([
    layers.Input(shape=(sequence_length, data.shape[-1])),
    layers.GRU(32),
    layers.Dense(1)
])
model1.summary()
test_results1 = train_and_evaluate_model(model1, train_dataset, val_dataset, test_dataset, model_name="Baseline GRU")

# Model 2: Stacked GRU
print("\n" + "="*50)
print("Building Stacked GRU Model")
print("="*50)
model2 = keras.Sequential([
    layers.Input(shape=(sequence_length, data.shape[-1])),
    layers.GRU(64, return_sequences=True),
    layers.GRU(64),
    layers.Dense(1)
])
model2.summary()
test_results2 = train_and_evaluate_model(model2, train_dataset, val_dataset, test_dataset, model_name="Stacked GRU")

# Model 3: Stacked LSTM
print("\n" + "="*50)
print("Building Stacked LSTM Model")
print("="*50)
model3 = keras.Sequential([
    layers.Input(shape=(sequence_length, data.shape[-1])),
    layers.LSTM(64, return_sequences=True),
    layers.LSTM(64),
    layers.Dense(1)
])
model3.summary()
test_results3 = train_and_evaluate_model(model3, train_dataset, val_dataset, test_dataset, model_name="Stacked LSTM")

# Model 4: CNN + RNN Hybrid
print("\n" + "="*50)
print("Building CNN+RNN Hybrid Model")
print("="*50)
model4 = keras.Sequential([
    layers.Input(shape=(sequence_length, data.shape[-1])),
    layers.Conv1D(64, 5, activation="relu"),
    layers.MaxPooling1D(3),
    layers.Conv1D(64, 5, activation="relu"),
    layers.GRU(64, return_sequences=True),
    layers.GRU(64),
    layers.Dense(1)
])
model4.summary()
test_results4 = train_and_evaluate_model(model4, train_dataset, val_dataset, test_dataset, model_name="CNN+RNN Hybrid")

# 6. Results Comparison
results = {
    "Baseline GRU": test_results1,
    "Stacked GRU": test_results2,
    "Stacked LSTM": test_results3,
    "CNN+RNN Hybrid": test_results4
}

results_df = pd.DataFrame.from_dict(results, orient='index', columns=['MSE', 'MAE'])
print("\nModel Comparison:")
display(results_df)

plt.figure(figsize=(10, 5))
plt.bar(results_df.index, results_df['MAE'])
plt.title("Model Comparison by Test MAE")
plt.ylabel("MAE")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# 8. Example Prediction Visualization
for samples, targets in test_dataset.take(1):
    pass

predictions = model4.predict(samples)

plt.figure(figsize=(12, 6))
plt.plot(targets[:50].numpy(), "b-", label="Actual Temperature")
plt.plot(predictions[:50], "r--", label="Predicted Temperature")
plt.title("Temperature Predictions vs Actual")
plt.xlabel("Time Steps")
plt.ylabel("Normalized Temperature")
plt.legend()
plt.show()